{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bfd1cd-637c-4717-b264-7fce308fef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "class PINNSolver:\n",
    "    def __init__(self, N_fields=1, m_vec=None, rho_m0=0.81, rho_r0=0.00027138, rho_l0=2.19,\n",
    "                 a0=1e-8, phi0=None, phi_dot0=None, t_span=(0.0, 1.0), t_eval=None,\n",
    "                 device=None, folder_name='results'):\n",
    "\n",
    "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        self.N_fields = N_fields\n",
    "        self.m_vec = m_vec if m_vec is not None else np.array([25.0]*N_fields)\n",
    "        self.rho_m0 = rho_m0\n",
    "        self.rho_r0 = rho_r0\n",
    "        self.rho_l0 = rho_l0\n",
    "\n",
    "        self.a0 = a0\n",
    "        self.phi0 = phi0 if phi0 is not None else np.array([1.0]*N_fields)\n",
    "        self.phi_dot0 = phi_dot0 if phi_dot0 is not None else np.array([0.0]*N_fields)\n",
    "        self.y0 = np.concatenate([[self.a0], self.phi0, self.phi_dot0])\n",
    "\n",
    "        self.t_span = t_span\n",
    "        self.t_eval = t_eval if t_eval is not None else np.logspace(np.log10(a0), np.log10(t_span[1]), 1000).astype(np.float32)\n",
    "\n",
    "        self.folder_name = folder_name\n",
    "        os.makedirs(self.folder_name, exist_ok=True)\n",
    "\n",
    "        self.model = self.PINN(num_layers=4, num_neurons=200, N_fields=self.N_fields).to(self.device)\n",
    "        self.m_vec_torch = torch.tensor(self.m_vec, dtype=torch.float32, device=self.device)\n",
    "        self.phi0_torch = torch.tensor(self.phi0.reshape(1, -1), device=self.device)\n",
    "        self.a0_torch = torch.tensor([[self.a0]], device=self.device)\n",
    "        self.t0_torch = torch.tensor([[0.0]], device=self.device)\n",
    "\n",
    "    class PINN(nn.Module):\n",
    "        def __init__(self, num_layers, num_neurons, N_fields):\n",
    "            super().__init__()\n",
    "            self.layers = nn.ModuleList()\n",
    "            self.layers.append(nn.Linear(1, num_neurons))\n",
    "            for _ in range(num_layers):\n",
    "                self.layers.append(nn.Linear(num_neurons, num_neurons))\n",
    "            self.layers.append(nn.Linear(num_neurons, 1 + N_fields))\n",
    "\n",
    "        def forward(self, t):\n",
    "            x = t\n",
    "            for layer in self.layers[:-1]:\n",
    "                z = layer(x)\n",
    "                x = z * torch.sin(z)\n",
    "            x = self.layers[-1](x)\n",
    "            a = torch.nn.functional.softplus(x[:, 0:1])\n",
    "            a = torch.clamp(a, min=1e-6)\n",
    "            phi = x[:, 1:]\n",
    "            return a, phi\n",
    "\n",
    "    def ode_system(self, t, y):\n",
    "        N = self.N_fields\n",
    "        a = y[0]\n",
    "        phi = y[1:N+1]\n",
    "        phi_dot = y[N+1:2*N+1]\n",
    "        kinetic = 0.5 * np.sum((phi_dot * a)**2)\n",
    "        potential = 0.5 * np.sum((self.m_vec**2) * (phi * a)**2)\n",
    "        H = np.sqrt((1/3) * (kinetic + potential + self.rho_m0 / a + self.rho_r0 / a**2 + self.rho_l0 * a**2))\n",
    "        a_dot = H\n",
    "        phi_ddot = - np.sqrt(3) * np.sqrt(0.5 * np.sum(phi_dot**2) +\n",
    "            0.5 * np.sum((self.m_vec**2) * phi**2) + self.rho_m0 / a**3 + self.rho_r0 / a**4 + self.rho_l0) * phi_dot \\\n",
    "            - (self.m_vec**2) * phi\n",
    "\n",
    "        dydt = np.zeros_like(y)\n",
    "        dydt[0] = a_dot\n",
    "        dydt[1:N+1] = phi_dot\n",
    "        dydt[N+1:2*N+1] = phi_ddot\n",
    "        return dydt\n",
    "\n",
    "    def solve_ode(self):\n",
    "        print(\"Solving ODE...\")\n",
    "        start_ode = time.time()\n",
    "        sol = solve_ivp(self.ode_system, self.t_span, self.y0, t_eval=self.t_eval, method='RK45')\n",
    "        print(f\"ODE solve time: {time.time() - start_ode:.2f} sec\")\n",
    "        self.a_sol = sol.y[0, :]\n",
    "        self.phi_sol = sol.y[1:1+self.N_fields, :]\n",
    "\n",
    "    def physics_loss(self, model, t):\n",
    "        a, phi = model(t)\n",
    "        a_t = torch.autograd.grad(a, t, torch.ones_like(a), create_graph=True)[0]\n",
    "        phi_t = torch.autograd.grad(phi, t, torch.ones_like(phi), create_graph=True)[0]\n",
    "        phi_tt = torch.autograd.grad(phi_t, t, torch.ones_like(phi_t), create_graph=True)[0]\n",
    "\n",
    "        kinetic = 0.5 * torch.sum((phi_t**2) * (a**2), dim=1, keepdim=True)\n",
    "        potential = 0.5 * torch.sum((self.m_vec_torch**2) * (phi**2) * (a**2), dim=1, keepdim=True)\n",
    "        Friedmann = a_t - torch.sqrt((1/3)*(kinetic + potential + self.rho_m0/a + self.rho_r0/a**2 + self.rho_l0 * a**2) + 1e-12)\n",
    "        sqsumrho = torch.sqrt(torch.full_like(t, 3.0)) * torch.sqrt(\n",
    "            0.5 * torch.sum(phi_t**2, dim=1, keepdim=True) +\n",
    "            0.5 * torch.sum((self.m_vec_torch**2) * phi**2, dim=1, keepdim=True) +\n",
    "            self.rho_m0/a**3 + self.rho_r0/a**4 + self.rho_l0 + 1e-12\n",
    "        )\n",
    "        KG = phi_tt + sqsumrho * phi_t + phi * (self.m_vec_torch**2)\n",
    "        return torch.mean(Friedmann**2) + torch.mean(KG**2)\n",
    "\n",
    "    def initial_loss(self, model):\n",
    "        a_pred0, phi_pred0 = model(self.t0_torch)\n",
    "        return 4.0 * torch.mean((a_pred0 - self.a0_torch)**2) + 30.0 * torch.mean((phi_pred0 - self.phi0_torch)**2)\n",
    "\n",
    "    def train(self, max_epochs_adam=10000, physics_weight=10.0, ic_weight=300.0, N_f=1000, print_every=500):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.4)\n",
    "\n",
    "        self.loss_history, self.physics_loss_history, self.ic_loss_history = [], [], []\n",
    "        print(\"Training PINN...\")\n",
    "        start = time.time()\n",
    "\n",
    "        for epoch in range(max_epochs_adam):\n",
    "            t_f = torch.linspace(0.0, 1.0, N_f, device=self.device).reshape(-1, 1).requires_grad_()\n",
    "            optimizer.zero_grad()\n",
    "            loss_physics_val = self.physics_loss(self.model, t_f)\n",
    "            loss_ic_val = self.initial_loss(self.model)\n",
    "            loss = physics_weight * loss_physics_val + ic_weight * loss_ic_val\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            self.loss_history.append(loss.item())\n",
    "            self.physics_loss_history.append(loss_physics_val.item())\n",
    "            self.ic_loss_history.append(loss_ic_val.item())\n",
    "\n",
    "            if epoch % print_every == 0 or epoch == max_epochs_adam - 1:\n",
    "                percent = 100 * epoch / max_epochs_adam\n",
    "                print(f\"[Adam] Epoch {epoch:5d}/{max_epochs_adam} ({percent:5.1f}%) | \"\n",
    "                      f\"Total Loss: {loss.item():.3e} | Physics: {loss_physics_val.item():.3e} | IC: {loss_ic_val.item():.3e}\")\n",
    "\n",
    "        print(f\"Training time: {time.time() - start:.2f} sec\")\n",
    "\n",
    "    def optimize_lbfgs(self):\n",
    "        print(\"Starting LBFGS optimization...\")\n",
    "        optimizer_lbfgs = optim.LBFGS(self.model.parameters(), lr=1.0, max_iter=5000, tolerance_grad=1e-9,\n",
    "                                      tolerance_change=1e-10, history_size=100, line_search_fn='strong_wolfe')\n",
    "\n",
    "        def closure():\n",
    "            optimizer_lbfgs.zero_grad()\n",
    "            t_f = torch.linspace(0.0, 1.0, 1000, device=self.device).reshape(-1, 1).requires_grad_()\n",
    "            loss = 10.0 * self.physics_loss(self.model, t_f) + 300.0 * self.initial_loss(self.model)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        optimizer_lbfgs.step(closure)\n",
    "\n",
    "    def evaluate(self):\n",
    "        t_plot = torch.tensor(self.t_eval, device=self.device).reshape(-1, 1).requires_grad_(True)\n",
    "        a_pred, phi_pred = self.model(t_plot)\n",
    "        self.a_pred = a_pred.detach().cpu().numpy().flatten()\n",
    "        self.phi_pred = phi_pred.detach().cpu().numpy().T\n",
    "\n",
    "    def evaluate_error_metrics(self):\n",
    "        mse_a = mean_squared_error(self.a_sol, self.a_pred)\n",
    "        mae_a = mean_absolute_error(self.a_sol, self.a_pred)\n",
    "        mse_phi, mae_phi = [], []\n",
    "        for i in range(self.N_fields):\n",
    "            mse_phi.append(mean_squared_error(self.phi_sol[i], self.phi_pred[i]))\n",
    "            mae_phi.append(mean_absolute_error(self.phi_sol[i], self.phi_pred[i]))\n",
    "\n",
    "        print(\"\\nEvaluation Metrics:\")\n",
    "        print(f\"  a(t)       -> MSE: {mse_a:.4e}, MAE: {mae_a:.4e}\")\n",
    "        for i, (mse_p, mae_p) in enumerate(zip(mse_phi, mae_phi)):\n",
    "            print(f\"  phi[{i}](t) -> MSE: {mse_p:.4e}, MAE: {mae_p:.4e}\")\n",
    "\n",
    "    def plot_results(self):\n",
    "        plt.figure(dpi=120)\n",
    "        plt.plot(self.t_eval, self.a_sol, 'k--', label='ODE a(t)')\n",
    "        plt.plot(self.t_eval, self.a_pred, 'r-', label='PINNs a(t)')\n",
    "        for i in range(min(self.N_fields, 5)):\n",
    "            plt.plot(self.t_eval, self.phi_sol[i, :], 'k--', alpha=0.5)\n",
    "            plt.plot(self.t_eval, self.phi_pred[i, :], 'r-', alpha=0.5)\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('t')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Comparison: ODE vs PINNs')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.savefig(os.path.join(self.folder_name, 'comparison.png'))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_losses(self):\n",
    "        plt.figure(dpi=120)\n",
    "        plt.plot(self.loss_history, label='Total Loss')\n",
    "        plt.plot(self.physics_loss_history, label='Physics Loss')\n",
    "        plt.plot(self.ic_loss_history, label='IC Loss')\n",
    "        plt.yscale('log')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss Curves During Training')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.folder_name, 'loss_curves.png'))\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    solver = PINNSolver()\n",
    "    solver.solve_ode()\n",
    "    solver.train()\n",
    "    solver.optimize_lbfgs()\n",
    "    solver.evaluate()\n",
    "    solver.evaluate_error_metrics()\n",
    "    solver.plot_results()\n",
    "    solver.plot_losses()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
